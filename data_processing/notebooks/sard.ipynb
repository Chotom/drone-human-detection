{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SARD - Search and rescue image dataset for person detection\n",
    "\n",
    "Follow this notebook to prepare SARD dataset.\n",
    "\n",
    "**Description:**\n",
    "- From the recordings with a total length of about 35 minutes, 1,981 single frames with people on them were singled out. In the selected images, the persons were manually tagged so that the set could be used to train the supervised model. Tagging of persons was done using the LabelImg tool. The image annotation consists of the position of the bounding box around each object of interest, the size of the bounding box in terms of width and height, and the corresponding class designation (Standing, Walking, Running, Sitting, Lying, Not Defined) for the person.\n",
    "\n",
    "**Annotations:**\n",
    "- in .csv format (one file for whole directory):\n",
    "```csv\n",
    "filename,width,height,class,xmin,ymin,xmax,ymax\n",
    "gss1307.jpg,1920,1080,person,309,666,358,740\n",
    "gss1307.jpg,1920,1080,person,1798,321,1836,358\n",
    "gss2100.jpg,1920,1080,person,1196,648,1256,700\n",
    "...\n",
    "```\n",
    "- bounding box in annotation in xmin, ymin, xmax, ymax format\n",
    "\n",
    "**Table of content:**\n",
    "\n",
    "0. Init - imports and data download\n",
    "1. Data annotation cleaning\n",
    "2. Data transformation\n",
    "3. Data visualization\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Init - imports and data download\n",
    "Download sard.zip files and extract them to `data/source/Sard` dir. After extract data should look like this:\n",
    "```\n",
    "data\n",
    "└───source\n",
    "    └───Sard\n",
    "        ├───train\n",
    "        └───val\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Uncomment below two lines to reload imported packages (in case of modifying them)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import xmltodict\n",
    "import json\n",
    "import cv2\n",
    "import pybboxes as pbx\n",
    "from pathlib import Path\n",
    "\n",
    "from prj_utils.consts import ROOT_DIR\n",
    "from data_processing.image_processing import plot_xywhn_annotated_image_from_file, get_brightness_stats, copy_annotated_images, get_number_of_objects_stats\n",
    "\n",
    "# Consts\n",
    "TRAIN_DIR = f'{ROOT_DIR}/data/source/Sard/train'\n",
    "VAL_DIR = f'{ROOT_DIR}/data/source/Sard/val'\n",
    "\n",
    "TRAIN_PROCESSED_DIR = f'{ROOT_DIR}/data/processed/Sard/train'\n",
    "VAL_PROCESSED_DIR = f'{ROOT_DIR}/data/processed/Sard/validate'\n",
    "TEST_PROCESSED_DIR = f'{ROOT_DIR}/data/processed/Sard/test'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data transformation\n",
    "- Transform labels from xml format to yolo .txt files\n",
    "- Split train data into train and validate dataset\n",
    "\n",
    "After this step processed data directory should look like this:\n",
    "```\n",
    "data\n",
    "└───processed\n",
    "    └───Sard\n",
    "        ├───test\n",
    "        │   ├───images\n",
    "        │   └───labels\n",
    "        ├───train\n",
    "        │   ├───images\n",
    "        │   └───labels\n",
    "        └───validate\n",
    "            ├───images\n",
    "            └───labels\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Transform labels from .csv format to yolo .txt files\n",
    "\n",
    "Yolo format:\n",
    "- One *.txt file per image (if no objects in image, no *.txt file is required).\n",
    "- One row per object.\n",
    "- Each row is `class x_center y_center scaled_width scaled_height` format, separated by space.\n",
    "- Box coordinates must be in normalized from 0 to 1. If your boxes are in pixels, divide x_center and width by image width, and y_center and height by image height.\n",
    "- Bounding box in annotation in xywhn format.\n",
    "- Class numbers are zero-indexed (start from 0).\n",
    "- Files are saved into `data/Sard/processed/test` and `data/Sard/processed/train` to images and labels directory.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_directory(input_directory, output_directory):\n",
    "    Path(f'{output_directory}/images').mkdir(parents=True, exist_ok=True)\n",
    "    Path(f'{output_directory}/labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    labels_file = [f for f in os.listdir(input_directory) if f.endswith('.csv')][0]\n",
    "    labels_filepath = os.path.join(input_directory, labels_file)\n",
    "    labels_df = pd.read_csv(labels_filepath)\n",
    "\n",
    "    files = [f for f in os.listdir(input_directory) if os.path.isfile(os.path.join(input_directory, f)) and not f.endswith('.csv')]\n",
    "\n",
    "    for image_file in files:\n",
    "        image_filename = Path(image_file).stem\n",
    "        image_filepath = os.path.join(input_directory, image_file)\n",
    "\n",
    "        if not image_filename[-1].isdigit():\n",
    "            print(f'Warning: file {image_file} is augmented - skipping file')\n",
    "            continue\n",
    "\n",
    "        output_image_filepath = f'{output_directory}/images/{image_file}'\n",
    "        output_labels_filepath = f'{output_directory}/labels/{image_filename}.txt'\n",
    "\n",
    "        file_labels_df = labels_df.loc[labels_df['filename'] == image_file]\n",
    "\n",
    "        if len(file_labels_df) < 1:\n",
    "            print(f'Warning: file {image_file} does not contain any objects - skipping file')\n",
    "            continue\n",
    "\n",
    "        yolo_labels = []\n",
    "\n",
    "        for _, label in file_labels_df.iterrows():\n",
    "            if label['class'] == 'person':\n",
    "                bbox = (int(label['xmin']), int(label['ymin']), int(label['xmax']), int(label['ymax']))\n",
    "                image_size = (label['width'], label['height'])\n",
    "                try:\n",
    "                    yolo_bbox = pbx.convert_bbox(bbox, image_size=image_size, from_type=\"voc\", to_type=\"yolo\")\n",
    "                except:\n",
    "                    print(f'Warning: wrong label in file {image_file}. This should happen only in case of row \"gss2104.jpg,1920,1080,person,527,464,527,464\" in \"val_labels.csv\" file. This label is incorrect, but removing it fixes the problem.')\n",
    "                    if image_file == 'gss2104.jpg':\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise\n",
    "                yolo_label = (0,) + yolo_bbox\n",
    "                yolo_labels.append(yolo_label)\n",
    "            else:\n",
    "                print(\"Warning: unknown object name\")\n",
    "\n",
    "        shutil.copyfile(image_filepath, output_image_filepath)\n",
    "\n",
    "        with open(output_labels_filepath, 'w') as f:\n",
    "            for label in yolo_labels:\n",
    "                line = ' '.join([str(l) for l in label])\n",
    "                f.write(f'{line}\\n')\n",
    "\n",
    "        #plot_xywhn_annotated_image_from_file(output_image_filepath, output_labels_filepath)\n",
    "\n",
    "process_directory(TRAIN_DIR, TRAIN_PROCESSED_DIR)\n",
    "process_directory(VAL_DIR, VAL_PROCESSED_DIR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Change validate set to test set and split train data into train and validate dataset\n",
    "\n",
    "Rename directory `data/Sard/processed/validate` to `data/Sard/processed/test`\n",
    "Move random probes from `data/Sard/processed/train` to `data/Sard/processed/validate`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "shutil.move(VAL_PROCESSED_DIR, TEST_PROCESSED_DIR)\n",
    "\n",
    "images_dir = f'{TRAIN_PROCESSED_DIR}/images'\n",
    "filenames = [f for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
    "split = int(0.75 * len(filenames))\n",
    "\n",
    "np.random.shuffle(filenames)\n",
    "train_filenames = filenames[:split]\n",
    "val_filenames = filenames[split:]\n",
    "\n",
    "Path(f'{VAL_PROCESSED_DIR}/images').mkdir(parents=True, exist_ok=True)\n",
    "Path(f'{VAL_PROCESSED_DIR}/labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#todo: move validate files to data/Heridal/processed/validate directory\n",
    "for file in val_filenames:\n",
    "    filename = Path(file).stem\n",
    "\n",
    "    image_filepath = f'{TRAIN_PROCESSED_DIR}/images/{file}'\n",
    "    label_filepath = f'{TRAIN_PROCESSED_DIR}/labels/{filename}.txt'\n",
    "\n",
    "    output_image_filepath = f'{VAL_PROCESSED_DIR}/images/{file}'\n",
    "    output_label_filepath = f'{VAL_PROCESSED_DIR}/labels/{filename}.txt'\n",
    "\n",
    "    shutil.move(image_filepath, output_image_filepath)\n",
    "    shutil.move(label_filepath, output_label_filepath)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
